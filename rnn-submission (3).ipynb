{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":114239,"databundleVersionId":14210809,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":5363782,"sourceType":"datasetVersion","datasetId":3109425},{"sourceId":13860626,"sourceType":"datasetVersion","datasetId":8830114},{"sourceId":13868189,"sourceType":"datasetVersion","datasetId":8835883},{"sourceId":13870234,"sourceType":"datasetVersion","datasetId":8837302},{"sourceId":13883778,"sourceType":"datasetVersion","datasetId":8845720}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nimport pandas as pd\nimport polars as pl\n\nimport numpy as np\n\nimport glob\nimport kaggle_evaluation.nfl_inference_server\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport polars as pl\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:58:55.946923Z","iopub.execute_input":"2025-11-26T18:58:55.947308Z","iopub.status.idle":"2025-11-26T18:58:55.952940Z","shell.execute_reply.started":"2025-11-26T18:58:55.947284Z","shell.execute_reply":"2025-11-26T18:58:55.951831Z"}},"outputs":[],"execution_count":110},{"cell_type":"code","source":"import kagglehub\nfrom kagglehub import KaggleDatasetAdapter\nfor dirname, _, filenames in os.walk('/kaggle/input/nfl-combine-results-dataset-2000-2022'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:58:55.963833Z","iopub.execute_input":"2025-11-26T18:58:55.964177Z","iopub.status.idle":"2025-11-26T18:58:55.979377Z","shell.execute_reply.started":"2025-11-26T18:58:55.964129Z","shell.execute_reply":"2025-11-26T18:58:55.978224Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/nfl-combine-results-dataset-2000-2022/2016_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2011_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2022_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2021_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2015_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2004_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2019_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2012_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2005_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2003_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2010_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2007_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2008_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2006_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2020_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2002_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2014_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2018_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2000_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2009_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2013_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2001_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2017_combine.csv\n","output_type":"stream"}],"execution_count":111},{"cell_type":"code","source":"def processPolars(test_polars, combine_polars):\n    test_polars = test_polars.with_columns(\n        [pl.col(\"player_birth_date\").str.to_datetime(format=\"%Y-%m-%d\").alias(\"datetime\"),\n    ]\n    ).drop(\"player_birth_date\").with_columns(\n        [pl.col(\"datetime\").dt.year().alias(\"player_born_year\")]\n    ).drop(\"datetime\").with_columns(\n        encoded_play_direction=pl.col(\"play_direction\").str.encode(\"hex\")\n    ).drop(\"play_direction\").with_columns(\n        play_direction=pl.col(\"encoded_play_direction\").str.to_integer(base=16, strict=False)\n    ).drop(\"encoded_play_direction\").with_columns(\n        test_polars[\"player_role\"].to_dummies()\n    ).drop(\"player_role\").with_columns(\n        test_polars[\"player_position\"].to_dummies()\n    ).drop(\"player_position\").with_columns(\n        test_polars[\"player_side\"].to_dummies()\n    ).drop(\"player_side\").with_columns(\n        pl.col(\"player_height\").str.extract(r\"(\\d+)-\", 1).cast(pl.Int32).alias(\"feet\"),\n        pl.col(\"player_height\").str.extract(r\"-(\\d+)\", 1).cast(pl.Int32).alias(\"inches\"),\n    ).with_columns(\n        (pl.col(\"feet\") * 12 + pl.col(\"inches\") + 2).alias(\"height\")\n    ).drop(\"player_height\").drop(\"inches\").drop(\"feet\")\n    \n    # Define expected columns from training\n    EXPECTED_POSITION_COLS = [\n        'player_position_CB', 'player_position_DE', 'player_position_DT',\n        'player_position_FB', 'player_position_FS', 'player_position_ILB',\n        'player_position_MLB', 'player_position_NT', 'player_position_OLB',\n        'player_position_QB', 'player_position_RB', 'player_position_S',\n        'player_position_SS', 'player_position_TE', 'player_position_WR'\n    ]\n    \n    EXPECTED_ROLE_COLS = [\n        'player_role_Defensive Coverage', 'player_role_Other Route Runner',\n        'player_role_Passer', 'player_role_Targeted Receiver'\n    ]\n    \n    EXPECTED_SIDE_COLS = ['player_side_Defense', 'player_side_Offense']\n    \n    # Remove any extra columns not in training\n    for col in test_polars.columns:\n        if col.startswith('player_position_') and col not in EXPECTED_POSITION_COLS:\n            test_polars = test_polars.drop(col)\n        if col.startswith('player_role_') and col not in EXPECTED_ROLE_COLS:\n            test_polars = test_polars.drop(col)\n        if col.startswith('player_side_') and col not in EXPECTED_SIDE_COLS:\n            test_polars = test_polars.drop(col)\n    \n    # Add missing columns as zeros\n    for col in EXPECTED_POSITION_COLS + EXPECTED_ROLE_COLS + EXPECTED_SIDE_COLS:\n        if col not in test_polars.columns:\n            test_polars = test_polars.with_columns(pl.lit(0).alias(col))\n    \n    # Now join with combine data\n    combined_test_polars = test_polars.join(\n        combine_polars, on=\"player_name\", how=\"full\"\n    ).drop(\"player_name_right\").with_columns(\n        encoded_player_name=pl.col(\"player_name\").str.encode(\"hex\")\n    ).with_columns(\n        player_name=pl.col(\"encoded_player_name\").str.to_integer(base=16, strict=False)\n    ).drop(\"encoded_player_name\").drop(\"Ht\").drop(\"Pos\").drop(\"player_weight\").with_columns(\n        (pl.col(\"y\") / 53.3).alias(\"y\"),\n        (pl.col(\"x\") / 120).alias(\"x\"),\n        (pl.col(\"ball_land_x\") / 120).alias(\"ball_land_x\"),\n        (pl.col(\"ball_land_y\") / 53.3).alias(\"ball_land_y\"),\n    ).drop(\"School\")\n\n    for i in range(4):\n        combined_test_polars = combined_test_polars.with_columns(\n        pl.lit(0.0).alias(f'dummy_feature_{i}')\n    )\n    \n    return combined_test_polars","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:58:55.980901Z","iopub.execute_input":"2025-11-26T18:58:55.981237Z","iopub.status.idle":"2025-11-26T18:58:56.000140Z","shell.execute_reply.started":"2025-11-26T18:58:55.981195Z","shell.execute_reply":"2025-11-26T18:58:55.998775Z"}},"outputs":[],"execution_count":112},{"cell_type":"code","source":"def processPolarsOutputs(test_polars, combine_polars):\n    test_polars = test_polars.with_columns(\n        #(pl.col(\"y\") / 53.3).alias(\"y\"),\n        #(pl.col(\"x\") / 120).alias(\"x\")\n    )\n    return test_polars","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:58:56.001446Z","iopub.execute_input":"2025-11-26T18:58:56.001762Z","iopub.status.idle":"2025-11-26T18:58:56.033735Z","shell.execute_reply.started":"2025-11-26T18:58:56.001741Z","shell.execute_reply":"2025-11-26T18:58:56.032757Z"}},"outputs":[],"execution_count":113},{"cell_type":"code","source":"def create_sequences(input_df, output_df):\n    \"\"\"\n    Create encoder-decoder sequences from input and output dataframes\n    \n    Args:\n        input_df: Tracking data BEFORE ball is thrown (encoder input)\n        output_df: Tracking data WHILE ball is in air (decoder target)\n    \n    Returns:\n        List of sequence dictionaries\n    \"\"\"\n    # Define feature columns\n    temporal_features = ['x', 'y', 's', 'a', 'dir', 'o']\n    \n    static_feature_cols = [\n        'height', 'Wt', '40yd', 'Vertical', 'Bench', \n        'Broad Jump', '3Cone', 'Shuttle', 'player_born_year',\n        'absolute_yardline_number', 'ball_land_x', 'ball_land_y',\n        'play_direction'\n    ] + [col for col in input_df.columns if col.startswith(\n        ('player_position_', 'player_role_', 'player_side_'))]\n    \n    # Convert to lazy if not already\n    input_lazy = input_df.lazy() if not isinstance(input_df, pl.LazyFrame) else input_df\n    output_lazy = output_df.lazy() if not isinstance(output_df, pl.LazyFrame) else output_df\n    \n    # Sort both dataframes\n    input_sorted = input_lazy.sort(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n    output_sorted = output_lazy.sort(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n    \n    # Group columns\n    group_cols = ['game_id', 'play_id', 'nfl_id']\n\n    #works since data is now in temporal format\n    \n    # Pre-compute aggregations using Polars' efficient group_by\n    input_agg = input_sorted.group_by(group_cols, maintain_order=True).agg([\n        *[pl.col(feat).alias(f'temporal_{feat}') for feat in temporal_features],\n        *[pl.col(col).first().alias(f'{col}_static') for col in static_feature_cols],\n        pl.len().alias('num_input_frames')\n    ])\n    \n    output_agg = output_sorted.group_by(group_cols, maintain_order=True).agg([\n        pl.col('x').alias('decoder_x'),\n        pl.col('y').alias('decoder_y'),\n        pl.len().alias('num_output_frames')\n    ])\n    \n    # Join the aggregated data and collect\n    joined = input_agg.join(output_agg, on=group_cols, how='inner').collect()\n    \n    # Convert to sequences\n    sequences = []\n    for row in joined.iter_rows(named=True):\n        # Extract temporal data - each feature is a list\n        temporal_data = np.column_stack([\n            row[f'temporal_{feat}'] for feat in temporal_features\n        ])\n        \n        # Extract static features\n        static_data = np.array([row[f'{col}_static'] for col in static_feature_cols], dtype=np.float32)\n        \n        # Repeat static features for each input frame\n        num_input_frames = row['num_input_frames']\n        static_repeated = np.tile(static_data, (num_input_frames, 1))\n        \n        # Combine temporal + static\n        encoder_input = np.concatenate([temporal_data, static_repeated], axis=1)\n        \n        # Decoder target\n        decoder_target = np.column_stack([\n            row['decoder_x'],\n            row['decoder_y']\n        ])\n        \n        sequences.append({\n            'encoder_input': encoder_input,\n            'decoder_target': decoder_target,\n            'static_features': static_data,\n            'num_input_frames': num_input_frames,\n            'num_output_frames': row['num_output_frames'],\n            'game_id': row['game_id'],\n            'play_id': row['play_id'],\n            'nfl_id': row['nfl_id']\n        })\n    \n    return sequences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:58:56.036003Z","iopub.execute_input":"2025-11-26T18:58:56.036333Z","iopub.status.idle":"2025-11-26T18:58:56.059048Z","shell.execute_reply.started":"2025-11-26T18:58:56.036311Z","shell.execute_reply":"2025-11-26T18:58:56.058181Z"}},"outputs":[],"execution_count":114},{"cell_type":"code","source":"class EncoderDecoderRNN(nn.Module):\n    def __init__(self, encoder_input_dim, static_dim, hidden_dim, num_layers=2):\n        super().__init__()\n        \n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n        \n        # ENCODER: Process input sequence (before ball thrown)\n        self.encoder = nn.LSTM(\n            input_size=encoder_input_dim,  # temporal (6) + static features\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=0.2 if num_layers > 1 else 0\n        )\n        \n        # DECODER: Generate output sequence (ball in air)\n        # Input: static features + previous position (for teacher forcing)\n        self.decoder = nn.LSTM(\n            input_size=static_dim + 2,  # static features + (x, y) from previous step\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=0.2 if num_layers > 1 else 0\n        )\n        \n        # Output layer\n        self.fc = nn.Linear(hidden_dim, 2)  # Predict (x, y)\n    \n    def forward(self, encoder_input, static_features, num_output_frames, \n                decoder_target=None, teacher_forcing_ratio=0.5):\n        \"\"\"\n        encoder_input: (batch, input_seq_len, encoder_input_dim)\n        static_features: (batch, static_dim)\n        num_output_frames: int or list of ints\n        decoder_target: (batch, output_seq_len, 2) - for teacher forcing during training\n        \"\"\"\n        batch_size = encoder_input.size(0)\n        device = encoder_input.device\n        \n        # ENCODE\n        encoder_output, (hidden, cell) = self.encoder(encoder_input)\n        # hidden, cell: (num_layers, batch, hidden_dim)\n        \n        # DECODE\n        # Start with last position from encoder input\n        decoder_input = encoder_input[:, -1, :2]  # Last (x, y) position\n        \n        # Prepare to collect outputs\n        if isinstance(num_output_frames, int):\n            max_output_frames = num_output_frames\n        elif torch.is_tensor(num_output_frames):\n            max_output_frames = num_output_frames.item() if num_output_frames.dim() == 0 else int(max(num_output_frames))\n        else:\n            max_output_frames = int(max(num_output_frames))\n        \n        outputs = []\n        \n        for t in range(max_output_frames):\n            # Concatenate previous position with static features\n            decoder_step_input = torch.cat([\n                decoder_input,  # (batch, 2)\n                static_features  # (batch, static_dim)\n            ], dim=1).unsqueeze(1)  # (batch, 1, static_dim + 2)\n            \n            # Decoder step\n            decoder_output, (hidden, cell) = self.decoder(\n                decoder_step_input, (hidden, cell)\n            )\n            \n            # Predict next position\n            prediction = self.fc(decoder_output.squeeze(1))  # (batch, 2)\n            outputs.append(prediction)\n            \n            # Teacher forcing: use actual target or prediction\n            if decoder_target is not None and t < decoder_target.size(1):\n                if torch.rand(1).item() < teacher_forcing_ratio:\n                    decoder_input = decoder_target[:, t, :]  # Use actual\n                else:\n                    decoder_input = prediction  # Use prediction\n            else:\n                decoder_input = prediction\n        \n        # Stack outputs\n        predictions = torch.stack(outputs, dim=1)  # (batch, max_output_frames, 2)\n        \n        return predictions\nclass EncoderDecoderDataset(Dataset):\n    def __init__(self, sequences):\n        self.sequences = sequences\n    \n    def __len__(self):\n        return len(self.sequences)\n    \n    def __getitem__(self, idx):\n        seq = self.sequences[idx]\n        return {\n            'encoder_input': torch.FloatTensor(seq['encoder_input']),\n            'decoder_target': torch.FloatTensor(seq['decoder_target']),\n            'static_features': torch.FloatTensor(seq['static_features']),\n            'num_input_frames': seq['num_input_frames'],\n            'num_output_frames': seq['num_output_frames']\n        }\n\ndef collate_fn_encoder_decoder(batch):\n    \"\"\"Handle variable length sequences\"\"\"\n    # Find max lengths\n    max_input_len = max(item['num_input_frames'] for item in batch)\n    max_output_len = max(item['num_output_frames'] for item in batch)\n    \n    batch_size = len(batch)\n    encoder_input_dim = batch[0]['encoder_input'].shape[1]\n    static_dim = batch[0]['static_features'].shape[0]\n    \n    # Initialize padded tensors\n    padded_encoder_input = torch.zeros(batch_size, max_input_len, encoder_input_dim)\n    padded_decoder_target = torch.zeros(batch_size, max_output_len, 2)\n    static_features = torch.zeros(batch_size, static_dim)\n    \n    input_lengths = []\n    output_lengths = []\n    \n    # Fill in data\n    for i, item in enumerate(batch):\n        input_len = item['num_input_frames']\n        output_len = item['num_output_frames']\n        \n        padded_encoder_input[i, :input_len, :] = item['encoder_input']\n        padded_decoder_target[i, :output_len, :] = item['decoder_target']\n        static_features[i] = item['static_features']\n        \n        input_lengths.append(input_len)\n        output_lengths.append(output_len)\n    \n    return {\n        'encoder_input': padded_encoder_input,\n        'decoder_target': padded_decoder_target,\n        'static_features': static_features,\n        'input_lengths': torch.LongTensor(input_lengths),\n        'output_lengths': torch.LongTensor(output_lengths)\n    }\n\n# Training loop adjustment\ndef train_epoch(model, dataloader, optimizer, device):\n    model.train()\n    total_loss = 0\n    \n    for batch in tqdm(dataloader, desc=\"Training\"):\n        encoder_input = batch['encoder_input'].to(device)\n        decoder_target = batch['decoder_target'].to(device)\n        static_features = batch['static_features'].to(device)\n        output_lengths = batch['output_lengths']\n        \n        optimizer.zero_grad()\n        \n        # Forward with teacher forcing\n        predictions = model(\n            encoder_input, \n            static_features,\n            output_lengths,\n            decoder_target=decoder_target,\n            teacher_forcing_ratio=0.5\n        )\n        \n        # Masked loss\n        loss = masked_mse_loss(predictions, decoder_target, output_lengths)\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    return total_loss / len(dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:58:56.060497Z","iopub.execute_input":"2025-11-26T18:58:56.060821Z","iopub.status.idle":"2025-11-26T18:58:56.092243Z","shell.execute_reply.started":"2025-11-26T18:58:56.060799Z","shell.execute_reply":"2025-11-26T18:58:56.090768Z"}},"outputs":[],"execution_count":115},{"cell_type":"code","source":"class EncoderDecoderRNN(nn.Module):\n    def __init__(self, encoder_input_dim, static_dim, hidden_dim, \n                 max_output_len=50, num_layers=2):\n        super().__init__()\n        \n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n        \n        # ENCODER\n        self.encoder = nn.LSTM(\n            input_size=encoder_input_dim,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=0.2 if num_layers > 1 else 0\n        )\n        \n        # ATTENTION\n        self.attention = Attention(hidden_dim)\n        \n        # POSITIONAL ENCODING\n        self.positional_encoding = LearnedPositionalEmbedding(\n            max_len=max_output_len,\n            embedding_dim=32\n        )\n        \n        # DECODER\n        decoder_input_size = 2 + static_dim + hidden_dim + 32\n        \n        self.decoder = nn.LSTM(\n            input_size=decoder_input_size,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=0.2 if num_layers > 1 else 0\n        )\n        \n        # Output layer\n        self.fc = nn.Linear(hidden_dim, 2)\n    \n    def forward(self, encoder_input, static_features, num_output_frames,\n                decoder_target=None, teacher_forcing_ratio=0.5):  # ‚Üê 4 spaces, not 8!\n        batch_size = encoder_input.size(0)\n        device = encoder_input.device\n        \n        # ENCODE\n        encoder_outputs, (hidden, cell) = self.encoder(encoder_input)\n        \n        # Start with last position\n        decoder_input = encoder_input[:, -1, :2]\n        \n        # Prepare max output frames\n        if isinstance(num_output_frames, int):\n            max_output_frames = num_output_frames\n        elif torch.is_tensor(num_output_frames):\n            max_output_frames = num_output_frames.item() if num_output_frames.dim() == 0 else int(max(num_output_frames))\n        else:\n            max_output_frames = int(max(num_output_frames))\n        \n        outputs = []\n        attention_weights_list = []\n        \n        for t in range(max_output_frames):\n            # Get attention context using top decoder hidden state\n            decoder_hidden_top = hidden[-1]  # (batch, hidden_dim)\n            context, attn_weights = self.attention(encoder_outputs, decoder_hidden_top)\n            \n            # Get positional encoding for current timestep\n            timestep_tensor = torch.full((batch_size,), t, dtype=torch.long, device=device)\n            pos_encoding = self.positional_encoding(timestep_tensor)  # (batch, 32)\n            \n            # Concatenate all decoder inputs\n            decoder_step_input = torch.cat([\n                decoder_input,      # (batch, 2)\n                static_features,    # (batch, static_dim)\n                context,           # (batch, hidden_dim)\n                pos_encoding       # (batch, 32)\n            ], dim=1).unsqueeze(1)  # (batch, 1, decoder_input_size)\n            \n            # Decoder step\n            decoder_output, (hidden, cell) = self.decoder(\n                decoder_step_input, (hidden, cell)\n            )\n            \n            # Predict next position\n            prediction = self.fc(decoder_output.squeeze(1))  # (batch, 2)\n            outputs.append(prediction)\n            attention_weights_list.append(attn_weights)\n            \n            # Teacher forcing\n            if decoder_target is not None and t < decoder_target.size(1):\n                if torch.rand(1).item() < teacher_forcing_ratio:\n                    decoder_input = decoder_target[:, t, :]\n                else:\n                    decoder_input = prediction\n            else:\n                decoder_input = prediction\n        \n        # Stack outputs\n        predictions = torch.stack(outputs, dim=1)  # (batch, max_output_frames, 2)\n        attention_weights = torch.stack(attention_weights_list, dim=1)\n        \n        return predictions, attention_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:58:56.093392Z","iopub.execute_input":"2025-11-26T18:58:56.093823Z","iopub.status.idle":"2025-11-26T18:58:56.121957Z","shell.execute_reply.started":"2025-11-26T18:58:56.093783Z","shell.execute_reply":"2025-11-26T18:58:56.120828Z"}},"outputs":[],"execution_count":116},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, hidden_dim):\n        super().__init__()\n        self.hidden_dim = hidden_dim\n        \n        # Learnable weights\n        self.W_encoder = nn.Linear(hidden_dim, hidden_dim)\n        self.W_decoder = nn.Linear(hidden_dim, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        \n    def forward(self, encoder_outputs, decoder_hidden):\n        \"\"\"\n        encoder_outputs: (batch, seq_len, hidden_dim)\n        decoder_hidden: (batch, hidden_dim)\n        \n        Returns:\n        context: (batch, hidden_dim)\n        attention_weights: (batch, seq_len)\n        \"\"\"\n        seq_len = encoder_outputs.size(1)\n        \n        # Expand decoder hidden to match encoder seq_len\n        decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, seq_len, 1)\n        # (batch, seq_len, hidden_dim)\n        \n        # Calculate attention scores\n        energy = torch.tanh(\n            self.W_encoder(encoder_outputs) + self.W_decoder(decoder_hidden)\n        )  # (batch, seq_len, hidden_dim)\n        \n        attention_scores = self.V(energy).squeeze(-1)  # (batch, seq_len)\n        \n        # Softmax to get attention weights\n        attention_weights = torch.softmax(attention_scores, dim=1)\n        # (batch, seq_len)\n        \n        # Weighted sum of encoder outputs\n        context = torch.bmm(\n            attention_weights.unsqueeze(1),  # (batch, 1, seq_len)\n            encoder_outputs  # (batch, seq_len, hidden_dim)\n        ).squeeze(1)  # (batch, hidden_dim)\n        \n        return context, attention_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:58:56.122934Z","iopub.execute_input":"2025-11-26T18:58:56.123372Z","iopub.status.idle":"2025-11-26T18:58:56.147475Z","shell.execute_reply.started":"2025-11-26T18:58:56.123349Z","shell.execute_reply":"2025-11-26T18:58:56.146355Z"}},"outputs":[],"execution_count":117},{"cell_type":"code","source":"class LearnedPositionalEmbedding(nn.Module):\n    def __init__(self, max_len, embedding_dim):\n        super().__init__()\n        self.embedding = nn.Embedding(max_len, embedding_dim)\n        \n    def forward(self, timestep):\n        \"\"\"\n        timestep: int or (batch,) tensor of timesteps\n        \"\"\"\n        if isinstance(timestep, int):\n            timestep = torch.tensor([timestep], device=self.embedding.weight.device)\n        return self.embedding(timestep)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:58:56.148929Z","iopub.execute_input":"2025-11-26T18:58:56.149444Z","iopub.status.idle":"2025-11-26T18:58:56.180784Z","shell.execute_reply.started":"2025-11-26T18:58:56.149391Z","shell.execute_reply":"2025-11-26T18:58:56.179524Z"}},"outputs":[],"execution_count":118},{"cell_type":"code","source":"model = torch.load('/kaggle/input/modelwithattention/best_nfl_model (3).pth',weights_only=\"True\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:58:56.182123Z","iopub.execute_input":"2025-11-26T18:58:56.182438Z","iopub.status.idle":"2025-11-26T18:58:56.233438Z","shell.execute_reply.started":"2025-11-26T18:58:56.182417Z","shell.execute_reply":"2025-11-26T18:58:56.232206Z"}},"outputs":[],"execution_count":119},{"cell_type":"code","source":"static_dih = model['static_dim']\nstatic_dih","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:58:56.236799Z","iopub.execute_input":"2025-11-26T18:58:56.237193Z","iopub.status.idle":"2025-11-26T18:58:56.244616Z","shell.execute_reply.started":"2025-11-26T18:58:56.237143Z","shell.execute_reply":"2025-11-26T18:58:56.243546Z"}},"outputs":[{"execution_count":120,"output_type":"execute_result","data":{"text/plain":"34"},"metadata":{}}],"execution_count":120},{"cell_type":"code","source":"awko_dim = model['hidden_dim']\nawko_dim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:58:56.245674Z","iopub.execute_input":"2025-11-26T18:58:56.245983Z","iopub.status.idle":"2025-11-26T18:58:56.270952Z","shell.execute_reply.started":"2025-11-26T18:58:56.245953Z","shell.execute_reply":"2025-11-26T18:58:56.269698Z"}},"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"32"},"metadata":{}}],"execution_count":121},{"cell_type":"code","source":"encoder_input_dim = model['encoder_input_dim']\nencoder_input_dim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:58:56.271918Z","iopub.execute_input":"2025-11-26T18:58:56.272195Z","iopub.status.idle":"2025-11-26T18:58:56.295454Z","shell.execute_reply.started":"2025-11-26T18:58:56.272145Z","shell.execute_reply":"2025-11-26T18:58:56.294220Z"}},"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"40"},"metadata":{}}],"execution_count":122},{"cell_type":"code","source":"train_path = '/kaggle/input/nfl-combine-results-dataset-2000-2022/'\ncombine_files = sorted(glob.glob(train_path + \"*_combine.csv\"))\ncombine_data = pd.concat([pd.read_csv(f) for f in combine_files], ignore_index=True)\n#loads the combine data\ncombine_polars = pl.from_pandas(combine_data)\ncombine_polars = combine_polars.rename({'Player': 'player_name'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:58:56.296357Z","iopub.execute_input":"2025-11-26T18:58:56.296582Z","iopub.status.idle":"2025-11-26T18:58:56.414417Z","shell.execute_reply.started":"2025-11-26T18:58:56.296565Z","shell.execute_reply":"2025-11-26T18:58:56.413337Z"}},"outputs":[],"execution_count":123},{"cell_type":"code","source":"test_input = pl.read_csv('/kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    if torch.cuda.is_available():\n        device = torch.device('cuda') # or 'cuda:0', 'cuda:1', etc.\n    else:\n        device = torch.device('cpu')\n    \n    new_model_input = processPolars(test_input,combine_polars)\n    new_model_input.describe()\n    new_model_input = new_model_input.fill_null(0)\n    test_filled = test.fill_null(0)\n    sequences = create_sequences(new_model_input,test_filled)\n\n    test_dataset = EncoderDecoderDataset(sequences)\n    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n                            collate_fn=collate_fn_encoder_decoder, num_workers=2)\n    max_frames_in_data = 0\n    for batch in train_loader:\n        max_frames_in_data = max(max_frames_in_data, max(batch['output_lengths']))\n    \n\n    checkpoint = torch.load('/kaggle/input/modelwithattention/best_nfl_model (3).pth',weights_only=\"True\")\n    encoder_input_dim = checkpoint['encoder_input_dim']\n    static_dim = checkpoint['static_dim']\n    hidden_dim = checkpoint['hidden_dim']\n    num_layers = checkpoint['num_layers']\n\n    model = EncoderDecoderRNN(\n        encoder_input_dim=encoder_input_dim,\n        static_dim=static_dim,\n        hidden_dim=128,\n        max_output_len=max_frames_in_data + 10,  # Add buffer\n        num_layers=2\n    ).to(device)\n\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.eval()\n    \n    all_predictions = []\n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Predicting\"):\n            encoder_input = batch['encoder_input'].to(device)\n            static_features = batch['static_features'].to(device)\n            output_lengths = batch['output_lengths']\n            \n            predictions = model(encoder_input, static_features, output_lengths,\n                              decoder_target=None, teacher_forcing_ratio=0.0)\n            \n            all_predictions.append(predictions.cpu())\n    \n    all_predictions = torch.cat(all_predictions, dim=0).numpy()\n    pred_x = all_predictions[:, :, 0] * 120    # Denormalize x\n    pred_y = all_predictions[:, :, 1] * 53.3   # Denormalize y\n    \n    # Flatten predictions to match test DataFrame format\n    pred_x_flat = pred_x.flatten()[:len(test)]\n    pred_y_flat = pred_y.flatten()[:len(test)]\n    \n    # CRITICAL FIX: Clone the test DataFrame and update x,y columns  \n    # This preserves all original columns (game_id, play_id, nfl_id, frame_id, etc.)\n    predictions = test.clone()\n    predictions = predictions.with_columns([\n        pl.Series('x', pred_x_flat.tolist()),\n        pl.Series('y', pred_y_flat.tolist())\n    ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:59:08.453838Z","iopub.execute_input":"2025-11-26T18:59:08.454134Z","iopub.status.idle":"2025-11-26T18:59:08.481496Z","shell.execute_reply.started":"2025-11-26T18:59:08.454113Z","shell.execute_reply":"2025-11-26T18:59:08.479674Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_38/4021620494.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnew_model_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessPolars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcombine_polars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mnew_model_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnew_model_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_model_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_null\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_input' is not defined"],"ename":"NameError","evalue":"name 'test_input' is not defined","output_type":"error"}],"execution_count":126},{"cell_type":"code","source":"def predict(test: pl.DataFrame, test_input: pl.DataFrame) -> pl.DataFrame | pd.DataFrame:\n    \"\"\"Replace this function with your inference code.\n    You can return either a Pandas or Polars dataframe, though Polars is recommended for performance.\n    Each batch of predictions (except the very first) must be returned within 5 minutes of the batch features being provided.\n    \"\"\"\n\n    if torch.cuda.is_available():\n        device = torch.device('cuda') # or 'cuda:0', 'cuda:1', etc.\n    else:\n        device = torch.device('cpu')\n    \n    new_model_input = processPolars(test_input,combine_polars)\n    new_model_input.describe()\n    new_model_input = new_model_input.fill_null(0)\n    test_filled = test.fill_null(0)\n    sequences = create_sequences(new_model_input,test_filled)\n\n    test_dataset = EncoderDecoderDataset(sequences)\n    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n                            collate_fn=collate_fn_encoder_decoder, num_workers=2)\n    max_frames_in_data = 0\n    for batch in train_loader:\n        max_frames_in_data = max(max_frames_in_data, max(batch['output_lengths']))\n    \n\n    checkpoint = torch.load('/kaggle/input/modelwithattention/best_nfl_model (3).pth',weights_only=\"True\")\n    encoder_input_dim = checkpoint['encoder_input_dim']\n    static_dim = checkpoint['static_dim']\n    hidden_dim = checkpoint['hidden_dim']\n    num_layers = checkpoint['num_layers']\n\n    model = EncoderDecoderRNN(\n        encoder_input_dim=encoder_input_dim,\n        static_dim=static_dim,\n        hidden_dim=128,\n        max_output_len=max_frames_in_data + 10,  # Add buffer\n        num_layers=2\n    ).to(device)\n\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.eval()\n    \n    all_predictions = []\n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Predicting\"):\n            encoder_input = batch['encoder_input'].to(device)\n            static_features = batch['static_features'].to(device)\n            output_lengths = batch['output_lengths']\n            \n            predictions = model(encoder_input, static_features, output_lengths,\n                              decoder_target=None, teacher_forcing_ratio=0.0)\n            \n            all_predictions.append(predictions.cpu())\n    \n    all_predictions = torch.cat(all_predictions, dim=0).numpy()\n    pred_x = all_predictions[:, :, 0] * 120    # Denormalize x\n    pred_y = all_predictions[:, :, 1] * 53.3   # Denormalize y\n    \n    # Flatten predictions to match test DataFrame format\n    pred_x_flat = pred_x.flatten()[:len(test)]\n    pred_y_flat = pred_y.flatten()[:len(test)]\n    \n    # CRITICAL FIX: Clone the test DataFrame and update x,y columns  \n    # This preserves all original columns (game_id, play_id, nfl_id, frame_id, etc.)\n    predictions = test.clone()\n    predictions = predictions.with_columns([\n        pl.Series('x', pred_x_flat.tolist()),\n        pl.Series('y', pred_y_flat.tolist())\n    ])\n    \n    assert isinstance(predictions, (pd.DataFrame, pl.DataFrame))\n    assert len(predictions) == len(test)\n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:58:56.422401Z","iopub.status.idle":"2025-11-26T18:58:56.422805Z","shell.execute_reply.started":"2025-11-26T18:58:56.422595Z","shell.execute_reply":"2025-11-26T18:58:56.422615Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inference_server = kaggle_evaluation.nfl_inference_server.NFLInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(('/kaggle/input/nfl-big-data-bowl-2026-prediction/',))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T18:58:56.427721Z","iopub.status.idle":"2025-11-26T18:58:56.428089Z","shell.execute_reply.started":"2025-11-26T18:58:56.427921Z","shell.execute_reply":"2025-11-26T18:58:56.427936Z"}},"outputs":[],"execution_count":null}]}