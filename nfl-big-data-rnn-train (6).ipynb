{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":114239,"databundleVersionId":14210809,"sourceType":"competition"},{"sourceId":5363782,"sourceType":"datasetVersion","datasetId":3109425,"isSourceIdPinned":false},{"sourceId":10999449,"sourceType":"datasetVersion","datasetId":6847229,"isSourceIdPinned":false}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import polars as pl\n#for lazy dataset processing","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:47.259744Z","iopub.execute_input":"2025-11-26T05:18:47.260554Z","iopub.status.idle":"2025-11-26T05:18:47.265928Z","shell.execute_reply.started":"2025-11-26T05:18:47.260491Z","shell.execute_reply":"2025-11-26T05:18:47.264559Z"}},"outputs":[],"execution_count":286},{"cell_type":"code","source":"# Install dependencies as needed:\n# pip install kagglehub[polars-datasets]\nimport kagglehub\nfrom kagglehub import KaggleDatasetAdapter\nfor dirname, _, filenames in os.walk('/kaggle/input/nfl-combine-results-dataset-2000-2022'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:47.313582Z","iopub.execute_input":"2025-11-26T05:18:47.313947Z","iopub.status.idle":"2025-11-26T05:18:47.321929Z","shell.execute_reply.started":"2025-11-26T05:18:47.313915Z","shell.execute_reply":"2025-11-26T05:18:47.320881Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/nfl-combine-results-dataset-2000-2022/2016_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2011_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2022_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2021_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2015_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2004_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2019_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2012_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2005_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2003_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2010_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2007_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2008_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2006_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2020_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2002_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2014_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2018_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2000_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2009_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2013_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2001_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2017_combine.csv\n","output_type":"stream"}],"execution_count":288},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:47.268218Z","iopub.execute_input":"2025-11-26T05:18:47.269189Z","iopub.status.idle":"2025-11-26T05:18:47.312369Z","shell.execute_reply.started":"2025-11-26T05:18:47.269152Z","shell.execute_reply":"2025-11-26T05:18:47.311313Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/test.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/nfl_inference_server.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/nfl_gateway.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/__init__.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/templates.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/base_gateway.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/relay.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/kaggle_evaluation.proto\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/__init__.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/__init__.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w17.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w05.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w10.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w03.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w18.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w05.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w11.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w12.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w16.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w06.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w18.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w10.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w02.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w08.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w12.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w13.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w15.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w03.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w13.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w15.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w16.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w01.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w04.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w14.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w14.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w09.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w01.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w07.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w11.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w06.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w04.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w09.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w17.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w07.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w08.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w02.csv\n/kaggle/input/2025-nfl-combine-dataset/2025 NFL Combine Dataset.xlsx\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2016_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2011_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2022_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2021_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2015_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2004_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2019_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2012_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2005_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2003_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2010_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2007_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2008_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2006_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2020_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2002_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2014_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2018_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2000_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2009_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2013_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2001_combine.csv\n/kaggle/input/nfl-combine-results-dataset-2000-2022/2017_combine.csv\n","output_type":"stream"}],"execution_count":287},{"cell_type":"code","source":"path = kagglehub.dataset_download(\"benhorne00/2025-nfl-combine-dataset\")\n\nprint(\"Path to dataset files:\", path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:47.324047Z","iopub.execute_input":"2025-11-26T05:18:47.324967Z","iopub.status.idle":"2025-11-26T05:18:48.258653Z","shell.execute_reply.started":"2025-11-26T05:18:47.324927Z","shell.execute_reply":"2025-11-26T05:18:48.257600Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/2025-nfl-combine-dataset\n","output_type":"stream"}],"execution_count":289},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T06:48:16.995080Z","iopub.execute_input":"2025-11-26T06:48:16.995640Z","iopub.status.idle":"2025-11-26T06:48:17.005418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:48.264923Z","iopub.execute_input":"2025-11-26T05:18:48.265188Z","iopub.status.idle":"2025-11-26T05:18:48.282254Z","shell.execute_reply.started":"2025-11-26T05:18:48.265171Z","shell.execute_reply":"2025-11-26T05:18:48.281329Z"}},"outputs":[],"execution_count":291},{"cell_type":"code","source":"class EncoderDecoderRNN(nn.Module):\n    def __init__(self, encoder_input_dim, static_dim, hidden_dim, \n                 max_output_len=50, num_layers=2):\n        super().__init__()\n        \n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n        \n        # ENCODER\n        self.encoder = nn.LSTM(\n            input_size=encoder_input_dim,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=0.2 if num_layers > 1 else 0\n        )\n        \n        # ATTENTION\n        self.attention = Attention(hidden_dim)\n        \n        # POSITIONAL ENCODING\n        self.positional_encoding = LearnedPositionalEmbedding(\n            max_len=max_output_len,\n            embedding_dim=32\n        )\n        \n        # DECODER\n        decoder_input_size = 2 + static_dim + hidden_dim + 32\n        \n        self.decoder = nn.LSTM(\n            input_size=decoder_input_size,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=0.2 if num_layers > 1 else 0\n        )\n        \n        # Output layer\n        self.fc = nn.Linear(hidden_dim, 2)\n    \n    def forward(self, encoder_input, static_features, num_output_frames,\n                decoder_target=None, teacher_forcing_ratio=0.5):  # ← 4 spaces, not 8!\n        batch_size = encoder_input.size(0)\n        device = encoder_input.device\n        \n        # ENCODE\n        encoder_outputs, (hidden, cell) = self.encoder(encoder_input)\n        \n        # Start with last position\n        decoder_input = encoder_input[:, -1, :2]\n        \n        # Prepare max output frames\n        if isinstance(num_output_frames, int):\n            max_output_frames = num_output_frames\n        elif torch.is_tensor(num_output_frames):\n            max_output_frames = num_output_frames.item() if num_output_frames.dim() == 0 else int(max(num_output_frames))\n        else:\n            max_output_frames = int(max(num_output_frames))\n        \n        outputs = []\n        attention_weights_list = []\n        \n        for t in range(max_output_frames):\n            # Get attention context using top decoder hidden state\n            decoder_hidden_top = hidden[-1]  # (batch, hidden_dim)\n            context, attn_weights = self.attention(encoder_outputs, decoder_hidden_top)\n            \n            # Get positional encoding for current timestep\n            timestep_tensor = torch.full((batch_size,), t, dtype=torch.long, device=device)\n            pos_encoding = self.positional_encoding(timestep_tensor)  # (batch, 32)\n            \n            # Concatenate all decoder inputs\n            decoder_step_input = torch.cat([\n                decoder_input,      # (batch, 2)\n                static_features,    # (batch, static_dim)\n                context,           # (batch, hidden_dim)\n                pos_encoding       # (batch, 32)\n            ], dim=1).unsqueeze(1)  # (batch, 1, decoder_input_size)\n            \n            # Decoder step\n            decoder_output, (hidden, cell) = self.decoder(\n                decoder_step_input, (hidden, cell)\n            )\n            \n            # Predict next position\n            prediction = self.fc(decoder_output.squeeze(1))  # (batch, 2)\n            outputs.append(prediction)\n            attention_weights_list.append(attn_weights)\n            \n            # Teacher forcing\n            if decoder_target is not None and t < decoder_target.size(1):\n                if torch.rand(1).item() < teacher_forcing_ratio:\n                    decoder_input = decoder_target[:, t, :]\n                else:\n                    decoder_input = prediction\n            else:\n                decoder_input = prediction\n        \n        # Stack outputs\n        predictions = torch.stack(outputs, dim=1)  # (batch, max_output_frames, 2)\n        attention_weights = torch.stack(attention_weights_list, dim=1)\n        \n        return predictions, attention_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:48.283249Z","iopub.execute_input":"2025-11-26T05:18:48.283569Z","iopub.status.idle":"2025-11-26T05:18:48.299492Z","shell.execute_reply.started":"2025-11-26T05:18:48.283544Z","shell.execute_reply":"2025-11-26T05:18:48.298272Z"}},"outputs":[],"execution_count":292},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, hidden_dim):\n        super().__init__()\n        self.hidden_dim = hidden_dim\n        \n        # Learnable weights\n        self.W_encoder = nn.Linear(hidden_dim, hidden_dim)\n        self.W_decoder = nn.Linear(hidden_dim, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        \n    def forward(self, encoder_outputs, decoder_hidden):\n        \"\"\"\n        encoder_outputs: (batch, seq_len, hidden_dim)\n        decoder_hidden: (batch, hidden_dim)\n        \n        Returns:\n        context: (batch, hidden_dim)\n        attention_weights: (batch, seq_len)\n        \"\"\"\n        seq_len = encoder_outputs.size(1)\n        \n        # Expand decoder hidden to match encoder seq_len\n        decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, seq_len, 1)\n        # (batch, seq_len, hidden_dim)\n        \n        # Calculate attention scores\n        energy = torch.tanh(\n            self.W_encoder(encoder_outputs) + self.W_decoder(decoder_hidden)\n        )  # (batch, seq_len, hidden_dim)\n        \n        attention_scores = self.V(energy).squeeze(-1)  # (batch, seq_len)\n        \n        # Softmax to get attention weights\n        attention_weights = torch.softmax(attention_scores, dim=1)\n        # (batch, seq_len)\n        \n        # Weighted sum of encoder outputs\n        context = torch.bmm(\n            attention_weights.unsqueeze(1),  # (batch, 1, seq_len)\n            encoder_outputs  # (batch, seq_len, hidden_dim)\n        ).squeeze(1)  # (batch, hidden_dim)\n        \n        return context, attention_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:48.302170Z","iopub.execute_input":"2025-11-26T05:18:48.302448Z","iopub.status.idle":"2025-11-26T05:18:48.320972Z","shell.execute_reply.started":"2025-11-26T05:18:48.302426Z","shell.execute_reply":"2025-11-26T05:18:48.320109Z"}},"outputs":[],"execution_count":293},{"cell_type":"code","source":"class LearnedPositionalEmbedding(nn.Module):\n    def __init__(self, max_len, embedding_dim):\n        super().__init__()\n        self.embedding = nn.Embedding(max_len, embedding_dim)\n        \n    def forward(self, timestep):\n        \"\"\"\n        timestep: int or (batch,) tensor of timesteps\n        \"\"\"\n        if isinstance(timestep, int):\n            timestep = torch.tensor([timestep], device=self.embedding.weight.device)\n        return self.embedding(timestep)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:48.321870Z","iopub.execute_input":"2025-11-26T05:18:48.322159Z","iopub.status.idle":"2025-11-26T05:18:48.341327Z","shell.execute_reply.started":"2025-11-26T05:18:48.322136Z","shell.execute_reply":"2025-11-26T05:18:48.340497Z"}},"outputs":[],"execution_count":294},{"cell_type":"code","source":"class EncoderDecoderDataset(Dataset):\n    def __init__(self, sequences):\n        self.sequences = sequences\n    \n    def __len__(self):\n        return len(self.sequences)\n    \n    def __getitem__(self, idx):\n        seq = self.sequences[idx]\n        return {\n            'encoder_input': torch.FloatTensor(seq['encoder_input']),\n            'decoder_target': torch.FloatTensor(seq['decoder_target']),\n            'static_features': torch.FloatTensor(seq['static_features']),\n            'num_input_frames': seq['num_input_frames'],\n            'num_output_frames': seq['num_output_frames']\n        }\n\ndef collate_fn_encoder_decoder(batch):\n    \"\"\"Handle variable length sequences\"\"\"\n    # Find max lengths\n    max_input_len = max(item['num_input_frames'] for item in batch)\n    max_output_len = max(item['num_output_frames'] for item in batch)\n    \n    batch_size = len(batch)\n    encoder_input_dim = batch[0]['encoder_input'].shape[1]\n    static_dim = batch[0]['static_features'].shape[0]\n    \n    # Initialize padded tensors\n    padded_encoder_input = torch.zeros(batch_size, max_input_len, encoder_input_dim)\n    padded_decoder_target = torch.zeros(batch_size, max_output_len, 2)\n    static_features = torch.zeros(batch_size, static_dim)\n    \n    input_lengths = []\n    output_lengths = []\n    \n    # Fill in data\n    for i, item in enumerate(batch):\n        input_len = item['num_input_frames']\n        output_len = item['num_output_frames']\n        \n        padded_encoder_input[i, :input_len, :] = item['encoder_input']\n        padded_decoder_target[i, :output_len, :] = item['decoder_target']\n        static_features[i] = item['static_features']\n        \n        input_lengths.append(input_len)\n        output_lengths.append(output_len)\n    \n    return {\n        'encoder_input': padded_encoder_input,\n        'decoder_target': padded_decoder_target,\n        'static_features': static_features,\n        'input_lengths': torch.LongTensor(input_lengths),\n        'output_lengths': torch.LongTensor(output_lengths)\n    }\n\n# Training loop adjustment\ndef train_epoch(model, dataloader, optimizer, device, teacher_forcing_ratio=0.5):\n    model.train()\n    total_loss = 0\n    \n    for batch in tqdm(dataloader, desc=\"Training\"):\n        encoder_input = batch['encoder_input'].to(device)\n        decoder_target = batch['decoder_target'].to(device)\n        static_features = batch['static_features'].to(device)\n        output_lengths = batch['output_lengths'].to(device)\n        \n        optimizer.zero_grad()\n        \n        # Forward with teacher forcing - UNPACK BOTH RETURNS\n        predictions, attention_weights = model(\n            encoder_input, \n            static_features,\n            max(output_lengths),\n            decoder_target=decoder_target,\n            teacher_forcing_ratio=teacher_forcing_ratio\n        )\n        \n        # Masked loss (just use predictions, ignore attention_weights for now)\n        loss = masked_mse_loss(predictions, decoder_target, output_lengths)\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    return total_loss / len(dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:48.342176Z","iopub.execute_input":"2025-11-26T05:18:48.342435Z","iopub.status.idle":"2025-11-26T05:18:48.359129Z","shell.execute_reply.started":"2025-11-26T05:18:48.342415Z","shell.execute_reply":"2025-11-26T05:18:48.358221Z"}},"outputs":[],"execution_count":295},{"cell_type":"code","source":"def masked_mse_loss(predictions, targets, lengths):\n    \"\"\"\n    Compute MSE loss only on valid (non-padded) positions\n    \n    predictions: (batch, max_seq_len, 2)\n    targets: (batch, max_seq_len, 2)\n    lengths: (batch,) - actual lengths for each sequence\n    \"\"\"\n    batch_size = predictions.size(0)\n    max_len = predictions.size(1)\n    \n    # Create mask: 1 for valid positions, 0 for padding\n    mask = torch.arange(max_len, device=predictions.device).expand(batch_size, max_len)\n    mask = (mask < lengths.unsqueeze(1)).float().unsqueeze(-1)  # (batch, max_len, 1)\n    \n    # Compute squared error\n    squared_error = (predictions - targets) ** 2\n    \n    # Apply mask and compute mean\n    masked_error = squared_error * mask\n    loss = masked_error.sum() / mask.sum()\n    \n    return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:48.359948Z","iopub.execute_input":"2025-11-26T05:18:48.360678Z","iopub.status.idle":"2025-11-26T05:18:48.378083Z","shell.execute_reply.started":"2025-11-26T05:18:48.360648Z","shell.execute_reply":"2025-11-26T05:18:48.377248Z"}},"outputs":[],"execution_count":296},{"cell_type":"code","source":"def validate_epoch(model, dataloader, device):\n    model.eval()\n    total_loss = 0\n    \n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Validation\"):\n            encoder_input = batch['encoder_input'].to(device)\n            decoder_target = batch['decoder_target'].to(device)\n            static_features = batch['static_features'].to(device)\n            output_lengths = batch['output_lengths'].to(device)\n            \n            # UNPACK BOTH RETURNS\n            predictions, attention_weights = model(\n                encoder_input,\n                static_features,\n                max(output_lengths),\n                decoder_target=None,  # No teacher forcing during validation\n                teacher_forcing_ratio=0.0\n            )\n            \n            loss = masked_mse_loss(predictions, decoder_target, output_lengths)\n            total_loss += loss.item()\n    \n    return total_loss / len(dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:48.379140Z","iopub.execute_input":"2025-11-26T05:18:48.379475Z","iopub.status.idle":"2025-11-26T05:18:48.396921Z","shell.execute_reply.started":"2025-11-26T05:18:48.379448Z","shell.execute_reply":"2025-11-26T05:18:48.395909Z"}},"outputs":[],"execution_count":297},{"cell_type":"code","source":"train_path = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/train/\"\ntest_path  = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/\"\n\nimport glob\n\n# Barcha train input fayllarni birlashtirish\ninput_files = sorted(glob.glob(train_path + \"input_2023_w*.csv\"))\noutput_files = sorted(glob.glob(train_path + \"output_2023_w*.csv\"))\n\ntrain_inputs = pd.concat([pd.read_csv(f) for f in input_files], ignore_index=True)\ntrain_outputs = pd.concat([pd.read_csv(f) for f in output_files], ignore_index=True)\n\nprint(train_inputs.shape, train_outputs.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:48.398293Z","iopub.execute_input":"2025-11-26T05:18:48.398690Z","iopub.status.idle":"2025-11-26T05:18:59.673358Z","shell.execute_reply.started":"2025-11-26T05:18:48.398577Z","shell.execute_reply":"2025-11-26T05:18:59.672358Z"}},"outputs":[{"name":"stdout","text":"(4880579, 23) (562936, 6)\n","output_type":"stream"}],"execution_count":298},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, optimizer, scheduler, \n                num_epochs, device, save_path='best_model.pth'):\n    \"\"\"\n    Complete training loop with validation and model saving\n    \"\"\"\n    best_val_loss = float('inf')\n    train_losses = []\n    val_losses = []\n    \n    for epoch in range(num_epochs):\n        print(f\"\\n{'='*50}\")\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        print(f\"{'='*50}\")\n        \n        # Train\n        train_loss = train_epoch(\n            model, train_loader, optimizer, device,\n            teacher_forcing_ratio=0.5  # Can decay this over epochs\n        )\n        train_losses.append(train_loss)\n        \n        # Validate\n        val_loss = validate_epoch(model, val_loader, device)\n        val_losses.append(val_loss)\n        \n        # Learning rate scheduling\n        if scheduler is not None:\n            scheduler.step(val_loss)\n        \n        print(f\"Train Loss: {train_loss:.6f}\")\n        print(f\"Val Loss:   {val_loss:.6f}\")\n        \n        # Save best model\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'train_loss': train_loss,\n                'val_loss': val_loss,\n            }, save_path)\n            print(f\"✓ Saved best model (val_loss: {val_loss:.6f})\")\n    \n    return train_losses, val_losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:59.674361Z","iopub.execute_input":"2025-11-26T05:18:59.674704Z","iopub.status.idle":"2025-11-26T05:18:59.682393Z","shell.execute_reply.started":"2025-11-26T05:18:59.674672Z","shell.execute_reply":"2025-11-26T05:18:59.681302Z"}},"outputs":[],"execution_count":299},{"cell_type":"code","source":"test_input = pd.read_csv(test_path + \"test_input.csv\")\ntest_data  = pd.read_csv(test_path + \"test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:59.683435Z","iopub.execute_input":"2025-11-26T05:18:59.683701Z","iopub.status.idle":"2025-11-26T05:18:59.814996Z","shell.execute_reply.started":"2025-11-26T05:18:59.683680Z","shell.execute_reply":"2025-11-26T05:18:59.814080Z"}},"outputs":[],"execution_count":300},{"cell_type":"code","source":"test_input.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:59.815792Z","iopub.execute_input":"2025-11-26T05:18:59.816008Z","iopub.status.idle":"2025-11-26T05:18:59.871523Z","shell.execute_reply.started":"2025-11-26T05:18:59.815985Z","shell.execute_reply":"2025-11-26T05:18:59.870757Z"}},"outputs":[{"execution_count":301,"output_type":"execute_result","data":{"text/plain":"            game_id       play_id       nfl_id      frame_id  \\\ncount  4.975300e+04  49753.000000  49753.00000  49753.000000   \nmean   2.024382e+09   2092.477760  51161.28143     16.011718   \nstd    4.050343e+05   1198.481594   5506.75297     10.568196   \nmin    2.024121e+09     63.000000  38588.00000      1.000000   \n25%    2.024121e+09   1201.000000  46142.00000      8.000000   \n50%    2.024122e+09   2090.000000  53496.00000     15.000000   \n75%    2.025011e+09   3156.000000  55949.00000     22.000000   \nmax    2.025011e+09   4154.000000  57801.00000     60.000000   \n\n       absolute_yardline_number  player_weight             x             y  \\\ncount              49753.000000   49753.000000  49753.000000  49753.000000   \nmean                  57.507185     210.669367     57.934714     26.721885   \nstd                   24.055066      22.353352     24.241947      9.792361   \nmin                   11.000000     165.000000      1.710000      0.980000   \n25%                   40.000000     195.000000     39.970000     19.120000   \n50%                   60.000000     205.000000     59.890000     26.730000   \n75%                   79.000000     228.000000     75.530000     34.290000   \nmax                  109.000000     347.000000    119.360000     51.390000   \n\n                  s             a           dir             o  \\\ncount  49753.000000  49753.000000  49753.000000  49753.000000   \nmean       3.008711      2.049136    175.150532    183.756428   \nstd        2.151394      1.287678    101.101264     98.530383   \nmin        0.000000      0.000000      0.010000      0.000000   \n25%        1.150000      1.040000     86.810000     94.430000   \n50%        2.750000      1.890000    169.880000    187.570000   \n75%        4.550000      2.920000    266.470000    273.290000   \nmax        9.560000      9.200000    359.990000    359.990000   \n\n       num_frames_output   ball_land_x   ball_land_y  \ncount       49753.000000  49753.000000  49753.000000  \nmean           11.524029     59.113787     27.115044  \nstd             4.799505     25.126137     14.603694  \nmin             5.000000      2.540000     -0.830000  \n25%             8.000000     43.770000     14.650000  \n50%            11.000000     63.070000     27.190001  \n75%            13.000000     75.900002     38.779999  \nmax            30.000000    117.099998     52.849998  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>game_id</th>\n      <th>play_id</th>\n      <th>nfl_id</th>\n      <th>frame_id</th>\n      <th>absolute_yardline_number</th>\n      <th>player_weight</th>\n      <th>x</th>\n      <th>y</th>\n      <th>s</th>\n      <th>a</th>\n      <th>dir</th>\n      <th>o</th>\n      <th>num_frames_output</th>\n      <th>ball_land_x</th>\n      <th>ball_land_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4.975300e+04</td>\n      <td>49753.000000</td>\n      <td>49753.00000</td>\n      <td>49753.000000</td>\n      <td>49753.000000</td>\n      <td>49753.000000</td>\n      <td>49753.000000</td>\n      <td>49753.000000</td>\n      <td>49753.000000</td>\n      <td>49753.000000</td>\n      <td>49753.000000</td>\n      <td>49753.000000</td>\n      <td>49753.000000</td>\n      <td>49753.000000</td>\n      <td>49753.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.024382e+09</td>\n      <td>2092.477760</td>\n      <td>51161.28143</td>\n      <td>16.011718</td>\n      <td>57.507185</td>\n      <td>210.669367</td>\n      <td>57.934714</td>\n      <td>26.721885</td>\n      <td>3.008711</td>\n      <td>2.049136</td>\n      <td>175.150532</td>\n      <td>183.756428</td>\n      <td>11.524029</td>\n      <td>59.113787</td>\n      <td>27.115044</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4.050343e+05</td>\n      <td>1198.481594</td>\n      <td>5506.75297</td>\n      <td>10.568196</td>\n      <td>24.055066</td>\n      <td>22.353352</td>\n      <td>24.241947</td>\n      <td>9.792361</td>\n      <td>2.151394</td>\n      <td>1.287678</td>\n      <td>101.101264</td>\n      <td>98.530383</td>\n      <td>4.799505</td>\n      <td>25.126137</td>\n      <td>14.603694</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2.024121e+09</td>\n      <td>63.000000</td>\n      <td>38588.00000</td>\n      <td>1.000000</td>\n      <td>11.000000</td>\n      <td>165.000000</td>\n      <td>1.710000</td>\n      <td>0.980000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.010000</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>2.540000</td>\n      <td>-0.830000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.024121e+09</td>\n      <td>1201.000000</td>\n      <td>46142.00000</td>\n      <td>8.000000</td>\n      <td>40.000000</td>\n      <td>195.000000</td>\n      <td>39.970000</td>\n      <td>19.120000</td>\n      <td>1.150000</td>\n      <td>1.040000</td>\n      <td>86.810000</td>\n      <td>94.430000</td>\n      <td>8.000000</td>\n      <td>43.770000</td>\n      <td>14.650000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.024122e+09</td>\n      <td>2090.000000</td>\n      <td>53496.00000</td>\n      <td>15.000000</td>\n      <td>60.000000</td>\n      <td>205.000000</td>\n      <td>59.890000</td>\n      <td>26.730000</td>\n      <td>2.750000</td>\n      <td>1.890000</td>\n      <td>169.880000</td>\n      <td>187.570000</td>\n      <td>11.000000</td>\n      <td>63.070000</td>\n      <td>27.190001</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.025011e+09</td>\n      <td>3156.000000</td>\n      <td>55949.00000</td>\n      <td>22.000000</td>\n      <td>79.000000</td>\n      <td>228.000000</td>\n      <td>75.530000</td>\n      <td>34.290000</td>\n      <td>4.550000</td>\n      <td>2.920000</td>\n      <td>266.470000</td>\n      <td>273.290000</td>\n      <td>13.000000</td>\n      <td>75.900002</td>\n      <td>38.779999</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.025011e+09</td>\n      <td>4154.000000</td>\n      <td>57801.00000</td>\n      <td>60.000000</td>\n      <td>109.000000</td>\n      <td>347.000000</td>\n      <td>119.360000</td>\n      <td>51.390000</td>\n      <td>9.560000</td>\n      <td>9.200000</td>\n      <td>359.990000</td>\n      <td>359.990000</td>\n      <td>30.000000</td>\n      <td>117.099998</td>\n      <td>52.849998</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":301},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:59.872303Z","iopub.execute_input":"2025-11-26T05:18:59.872537Z","iopub.status.idle":"2025-11-26T05:18:59.876891Z","shell.execute_reply.started":"2025-11-26T05:18:59.872514Z","shell.execute_reply":"2025-11-26T05:18:59.875937Z"}},"outputs":[],"execution_count":302},{"cell_type":"code","source":"def processPolarsOutputs(test_polars, combine_polars):\n    test_polars = test_polars.with_columns(\n        (pl.col(\"y\") / 53.3).alias(\"y\"),\n        (pl.col(\"x\") / 120).alias(\"x\")\n    )\n    return test_polars","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:59.877959Z","iopub.execute_input":"2025-11-26T05:18:59.878316Z","iopub.status.idle":"2025-11-26T05:18:59.890955Z","shell.execute_reply.started":"2025-11-26T05:18:59.878289Z","shell.execute_reply":"2025-11-26T05:18:59.890139Z"}},"outputs":[],"execution_count":303},{"cell_type":"code","source":"def processPolars(test_polars, combine_polars):\n    test_polars = test_polars.with_columns(\n        [pl.col(\"player_birth_date\").str.to_datetime(format=\"%Y-%m-%d\").alias(\"datetime\"),\n    ]\n    ).drop(\"player_birth_date\").with_columns(\n        [pl.col(\"datetime\").dt.year().alias(\"player_born_year\")]\n    ).drop(\"datetime\").with_columns(\n        encoded_play_direction=pl.col(\"play_direction\").str.encode(\"hex\")\n    ).drop(\"play_direction\").with_columns(\n        play_direction=pl.col(\"encoded_play_direction\").str.to_integer(base=16, strict=False)\n    ).drop(\"encoded_play_direction\").with_columns(\n        test_polars[\"player_role\"].to_dummies()\n    ).drop(\"player_role\").with_columns(\n        test_polars[\"player_position\"].to_dummies()\n    ).drop(\"player_position\").with_columns(\n        test_polars[\"player_side\"].to_dummies()\n    ).drop(\"player_side\").with_columns(\n        pl.col(\"player_height\").str.extract(r\"(\\d+)-\", 1).cast(pl.Int32).alias(\"feet\"),\n        pl.col(\"player_height\").str.extract(r\"-(\\d+)\", 1).cast(pl.Int32).alias(\"inches\"),\n    ).with_columns(\n        (pl.col(\"feet\") * 12 + pl.col(\"inches\") + 2).alias(\"height\")\n    ).drop(\"player_height\").drop(\"inches\").drop(\"feet\")\n    \n    # Define expected columns from training\n    EXPECTED_POSITION_COLS = [\n        'player_position_CB', 'player_position_DE', 'player_position_DT',\n        'player_position_FB', 'player_position_FS', 'player_position_ILB',\n        'player_position_MLB', 'player_position_NT', 'player_position_OLB',\n        'player_position_QB', 'player_position_RB', 'player_position_S',\n        'player_position_SS', 'player_position_TE', 'player_position_WR'\n    ]\n    \n    EXPECTED_ROLE_COLS = [\n        'player_role_Defensive Coverage', 'player_role_Other Route Runner',\n        'player_role_Passer', 'player_role_Targeted Receiver'\n    ]\n    \n    EXPECTED_SIDE_COLS = ['player_side_Defense', 'player_side_Offense']\n    \n    # Remove any extra columns not in training\n    for col in test_polars.columns:\n        if col.startswith('player_position_') and col not in EXPECTED_POSITION_COLS:\n            test_polars = test_polars.drop(col)\n        if col.startswith('player_role_') and col not in EXPECTED_ROLE_COLS:\n            test_polars = test_polars.drop(col)\n        if col.startswith('player_side_') and col not in EXPECTED_SIDE_COLS:\n            test_polars = test_polars.drop(col)\n    \n    # Add missing columns as zeros\n    for col in EXPECTED_POSITION_COLS + EXPECTED_ROLE_COLS + EXPECTED_SIDE_COLS:\n        if col not in test_polars.columns:\n            test_polars = test_polars.with_columns(pl.lit(0).alias(col))\n    \n    # Now join with combine data\n    combined_test_polars = test_polars.join(\n        combine_polars, on=\"player_name\", how=\"full\"\n    ).drop(\"player_name_right\").with_columns(\n        encoded_player_name=pl.col(\"player_name\").str.encode(\"hex\")\n    ).with_columns(\n        player_name=pl.col(\"encoded_player_name\").str.to_integer(base=16, strict=False)\n    ).drop(\"encoded_player_name\").drop(\"Ht\").drop(\"Pos\").drop(\"player_weight\").with_columns(\n        (pl.col(\"y\") / 53.3).alias(\"y\"),\n        (pl.col(\"x\") / 120).alias(\"x\"),\n        (pl.col(\"ball_land_x\") / 120).alias(\"ball_land_x\"),\n        (pl.col(\"ball_land_y\") / 53.3).alias(\"ball_land_y\"),\n    ).drop(\"School\")\n    \n    return combined_test_polars","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:59.894793Z","iopub.execute_input":"2025-11-26T05:18:59.895038Z","iopub.status.idle":"2025-11-26T05:18:59.908106Z","shell.execute_reply.started":"2025-11-26T05:18:59.895020Z","shell.execute_reply":"2025-11-26T05:18:59.907329Z"}},"outputs":[],"execution_count":304},{"cell_type":"code","source":"# Barcha train input fayllarni birlashtirish\ntrain_path = '/kaggle/input/nfl-combine-results-dataset-2000-2022/'\ncombine_files = sorted(glob.glob(train_path + \"*_combine.csv\"))\n\ncombine_data = pd.concat([pd.read_csv(f) for f in combine_files], ignore_index=True)\n#loads the combine data\ncombine_polars = pl.from_pandas(combine_data)\ncombine_polars = combine_polars.rename({'Player': 'player_name'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:59.908818Z","iopub.execute_input":"2025-11-26T05:18:59.909031Z","iopub.status.idle":"2025-11-26T05:18:59.997071Z","shell.execute_reply.started":"2025-11-26T05:18:59.909015Z","shell.execute_reply":"2025-11-26T05:18:59.996271Z"}},"outputs":[],"execution_count":305},{"cell_type":"code","source":"test_polars = processPolars(pl.from_pandas(test_input),combine_polars)\ntrain_input_polars = processPolars(pl.from_pandas(train_inputs),combine_polars)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:18:59.997869Z","iopub.execute_input":"2025-11-26T05:18:59.998071Z","iopub.status.idle":"2025-11-26T05:19:07.828065Z","shell.execute_reply.started":"2025-11-26T05:18:59.998052Z","shell.execute_reply":"2025-11-26T05:19:07.827153Z"}},"outputs":[],"execution_count":306},{"cell_type":"code","source":"test_data_polars = pl.from_pandas(test_data)\ntrain_output_polars = processPolarsOutputs(pl.from_pandas(train_outputs),combine_polars)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:19:07.828908Z","iopub.execute_input":"2025-11-26T05:19:07.829150Z","iopub.status.idle":"2025-11-26T05:19:07.842874Z","shell.execute_reply.started":"2025-11-26T05:19:07.829129Z","shell.execute_reply":"2025-11-26T05:19:07.842139Z"}},"outputs":[],"execution_count":307},{"cell_type":"code","source":"train_output_polars.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:19:07.843695Z","iopub.execute_input":"2025-11-26T05:19:07.844004Z","iopub.status.idle":"2025-11-26T05:19:07.902012Z","shell.execute_reply.started":"2025-11-26T05:19:07.843980Z","shell.execute_reply":"2025-11-26T05:19:07.901199Z"}},"outputs":[{"execution_count":308,"output_type":"execute_result","data":{"text/plain":"shape: (9, 7)\n┌────────────┬───────────────┬─────────────┬──────────────┬──────────┬──────────┬──────────┐\n│ statistic  ┆ game_id       ┆ play_id     ┆ nfl_id       ┆ frame_id ┆ x        ┆ y        │\n│ ---        ┆ ---           ┆ ---         ┆ ---          ┆ ---      ┆ ---      ┆ ---      │\n│ str        ┆ f64           ┆ f64         ┆ f64          ┆ f64      ┆ f64      ┆ f64      │\n╞════════════╪═══════════════╪═════════════╪══════════════╪══════════╪══════════╪══════════╡\n│ count      ┆ 562936.0      ┆ 562936.0    ┆ 562936.0     ┆ 562936.0 ┆ 562936.0 ┆ 562936.0 │\n│ null_count ┆ 0.0           ┆ 0.0         ┆ 0.0          ┆ 0.0      ┆ 0.0      ┆ 0.0      │\n│ mean       ┆ 2.0232e9      ┆ 2219.785841 ┆ 49647.292742 ┆ 7.865402 ┆ 0.502148 ┆ 0.499407 │\n│ std        ┆ 202018.858446 ┆ 1246.443129 ┆ 5089.634979  ┆ 5.923855 ┆ 0.210744 ┆ 0.252274 │\n│ min        ┆ 2.0231e9      ┆ 54.0        ┆ 30842.0      ┆ 1.0      ┆ 0.000167 ┆ 0.006191 │\n│ 25%        ┆ 2.0231e9      ┆ 1185.0      ┆ 45395.0      ┆ 4.0      ┆ 0.358333 ┆ 0.279737 │\n│ 50%        ┆ 2.0231e9      ┆ 2207.0      ┆ 52423.0      ┆ 7.0      ┆ 0.500667 ┆ 0.496248 │\n│ 75%        ┆ 2.0231e9      ┆ 3278.0      ┆ 54496.0      ┆ 11.0     ┆ 0.644333 ┆ 0.7197   │\n│ max        ┆ 2.0240e9      ┆ 5258.0      ┆ 56673.0      ┆ 94.0     ┆ 1.006917 ┆ 1.00788  │\n└────────────┴───────────────┴─────────────┴──────────────┴──────────┴──────────┴──────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (9, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>game_id</th><th>play_id</th><th>nfl_id</th><th>frame_id</th><th>x</th><th>y</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>562936.0</td><td>562936.0</td><td>562936.0</td><td>562936.0</td><td>562936.0</td><td>562936.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>2.0232e9</td><td>2219.785841</td><td>49647.292742</td><td>7.865402</td><td>0.502148</td><td>0.499407</td></tr><tr><td>&quot;std&quot;</td><td>202018.858446</td><td>1246.443129</td><td>5089.634979</td><td>5.923855</td><td>0.210744</td><td>0.252274</td></tr><tr><td>&quot;min&quot;</td><td>2.0231e9</td><td>54.0</td><td>30842.0</td><td>1.0</td><td>0.000167</td><td>0.006191</td></tr><tr><td>&quot;25%&quot;</td><td>2.0231e9</td><td>1185.0</td><td>45395.0</td><td>4.0</td><td>0.358333</td><td>0.279737</td></tr><tr><td>&quot;50%&quot;</td><td>2.0231e9</td><td>2207.0</td><td>52423.0</td><td>7.0</td><td>0.500667</td><td>0.496248</td></tr><tr><td>&quot;75%&quot;</td><td>2.0231e9</td><td>3278.0</td><td>54496.0</td><td>11.0</td><td>0.644333</td><td>0.7197</td></tr><tr><td>&quot;max&quot;</td><td>2.0240e9</td><td>5258.0</td><td>56673.0</td><td>94.0</td><td>1.006917</td><td>1.00788</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":308},{"cell_type":"code","source":"train_input_polars.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:19:07.902719Z","iopub.execute_input":"2025-11-26T05:19:07.902929Z","iopub.status.idle":"2025-11-26T05:19:09.676069Z","shell.execute_reply.started":"2025-11-26T05:19:07.902912Z","shell.execute_reply":"2025-11-26T05:19:09.675182Z"}},"outputs":[{"execution_count":309,"output_type":"execute_result","data":{"text/plain":"shape: (9, 48)\n┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n│ statistic ┆ game_id   ┆ play_id   ┆ player_to ┆ … ┆ Bench     ┆ Broad     ┆ 3Cone     ┆ Shuttle  │\n│ ---       ┆ ---       ┆ ---       ┆ _predict  ┆   ┆ ---       ┆ Jump      ┆ ---       ┆ ---      │\n│ str       ┆ f64       ┆ f64       ┆ ---       ┆   ┆ f64       ┆ ---       ┆ f64       ┆ f64      │\n│           ┆           ┆           ┆ f64       ┆   ┆           ┆ f64       ┆           ┆          │\n╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n│ count     ┆ 4.94172e6 ┆ 4.94172e6 ┆ 4.94172e6 ┆ … ┆ 2.060714e ┆ 2.717257e ┆ 1.887875e ┆ 1.956297 │\n│           ┆           ┆           ┆           ┆   ┆ 6         ┆ 6         ┆ 6         ┆ e6       │\n│ null_coun ┆ 6826.0    ┆ 6826.0    ┆ 6826.0    ┆ … ┆ 2.887832e ┆ 2.231289e ┆ 3.060671e ┆ 2.992249 │\n│ t         ┆           ┆           ┆           ┆   ┆ 6         ┆ 6         ┆ 6         ┆ e6       │\n│ mean      ┆ 2.0232e9  ┆ 2194.4918 ┆ 0.266164  ┆ … ┆ 16.929729 ┆ 122.25434 ┆ 6.970367  ┆ 4.237323 │\n│           ┆           ┆ 6         ┆           ┆   ┆           ┆           ┆           ┆          │\n│ std       ┆ 201188.20 ┆ 1246.4942 ┆ null      ┆ … ┆ 4.748011  ┆ 6.225874  ┆ 0.215392  ┆ 0.148692 │\n│           ┆ 1408      ┆ 17        ┆           ┆   ┆           ┆           ┆           ┆          │\n│ min       ┆ 2.0231e9  ┆ 54.0      ┆ 0.0       ┆ … ┆ 2.0       ┆ 74.0      ┆ 6.28      ┆ 3.73     │\n│ 25%       ┆ 2.0231e9  ┆ 1148.0    ┆ null      ┆ … ┆ 14.0      ┆ 118.0     ┆ 6.82      ┆ 4.13     │\n│ 50%       ┆ 2.0231e9  ┆ 2170.0    ┆ null      ┆ … ┆ 17.0      ┆ 122.0     ┆ 6.96      ┆ 4.23     │\n│ 75%       ┆ 2.0231e9  ┆ 3244.0    ┆ null      ┆ … ┆ 19.0      ┆ 126.0     ┆ 7.09      ┆ 4.34     │\n│ max       ┆ 2.0240e9  ┆ 5258.0    ┆ 1.0       ┆ … ┆ 49.0      ┆ 147.0     ┆ 9.12      ┆ 5.56     │\n└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (9, 48)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>game_id</th><th>play_id</th><th>player_to_predict</th><th>nfl_id</th><th>frame_id</th><th>absolute_yardline_number</th><th>player_name</th><th>x</th><th>y</th><th>s</th><th>a</th><th>dir</th><th>o</th><th>num_frames_output</th><th>ball_land_x</th><th>ball_land_y</th><th>player_born_year</th><th>play_direction</th><th>player_role_Defensive Coverage</th><th>player_role_Other Route Runner</th><th>player_role_Passer</th><th>player_role_Targeted Receiver</th><th>player_position_CB</th><th>player_position_DE</th><th>player_position_DT</th><th>player_position_FB</th><th>player_position_FS</th><th>player_position_ILB</th><th>player_position_MLB</th><th>player_position_NT</th><th>player_position_OLB</th><th>player_position_QB</th><th>player_position_RB</th><th>player_position_S</th><th>player_position_SS</th><th>player_position_TE</th><th>player_position_WR</th><th>player_side_Defense</th><th>player_side_Offense</th><th>height</th><th>Wt</th><th>40yd</th><th>Vertical</th><th>Bench</th><th>Broad Jump</th><th>3Cone</th><th>Shuttle</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>29368.0</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>4.94172e6</td><td>3.356672e6</td><td>2.94157e6</td><td>2.768143e6</td><td>2.060714e6</td><td>2.717257e6</td><td>1.887875e6</td><td>1.956297e6</td></tr><tr><td>&quot;null_count&quot;</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>4.919178e6</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>6826.0</td><td>1.591874e6</td><td>2.006976e6</td><td>2.180403e6</td><td>2.887832e6</td><td>2.231289e6</td><td>3.060671e6</td><td>2.992249e6</td></tr><tr><td>&quot;mean&quot;</td><td>2.0232e9</td><td>2194.49186</td><td>0.266164</td><td>49510.873115</td><td>16.136608</td><td>60.549741</td><td>5.1929e18</td><td>0.504177</td><td>0.503034</td><td>3.012435</td><td>2.115664</td><td>180.508896</td><td>181.631006</td><td>11.643935</td><td>0.504268</td><td>0.499675</td><td>1996.758192</td><td>2.4846e11</td><td>0.545077</td><td>0.289301</td><td>0.085022</td><td>0.0806</td><td>0.214003</td><td>0.003445</td><td>0.000635</td><td>0.004222</td><td>0.100315</td><td>0.062074</td><td>0.040468</td><td>0.000244</td><td>0.041975</td><td>0.08588</td><td>0.063726</td><td>0.002785</td><td>0.079425</td><td>0.084413</td><td>0.216356</td><td>0.545077</td><td>0.454923</td><td>75.079607</td><td>213.250433</td><td>4.542937</td><td>35.452883</td><td>16.929729</td><td>122.25434</td><td>6.970367</td><td>4.237323</td></tr><tr><td>&quot;std&quot;</td><td>201188.201408</td><td>1246.494217</td><td>null</td><td>5205.537597</td><td>11.136018</td><td>23.062136</td><td>3.1525e17</td><td>0.195803</td><td>0.187099</td><td>2.224392</td><td>1.41397</td><td>100.705848</td><td>98.01594</td><td>5.332433</td><td>0.21083</td><td>0.289732</td><td>2.974658</td><td>2.4478e11</td><td>0.497964</td><td>0.453438</td><td>0.278914</td><td>0.27222</td><td>0.410129</td><td>0.058589</td><td>0.025195</td><td>0.06484</td><td>0.30042</td><td>0.241289</td><td>0.197055</td><td>0.015633</td><td>0.200532</td><td>0.280187</td><td>0.244265</td><td>0.052702</td><td>0.270401</td><td>0.278006</td><td>0.41176</td><td>0.497964</td><td>0.497964</td><td>2.255597</td><td>22.720532</td><td>0.139525</td><td>3.137675</td><td>4.748011</td><td>6.225874</td><td>0.215392</td><td>0.148692</td></tr><tr><td>&quot;min&quot;</td><td>2.0231e9</td><td>54.0</td><td>0.0</td><td>30842.0</td><td>1.0</td><td>11.0</td><td>4.7844e18</td><td>0.003417</td><td>0.011632</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>5.0</td><td>-0.043833</td><td>-0.073358</td><td>1984.0</td><td>1.8186e9</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>68.0</td><td>144.0</td><td>4.22</td><td>17.5</td><td>2.0</td><td>74.0</td><td>6.28</td><td>3.73</td></tr><tr><td>&quot;25%&quot;</td><td>2.0231e9</td><td>1148.0</td><td>null</td><td>45185.0</td><td>8.0</td><td>41.0</td><td>4.9208e18</td><td>0.35525</td><td>0.357223</td><td>1.09</td><td>1.01</td><td>90.91</td><td>91.8</td><td>8.0</td><td>0.355083</td><td>0.249343</td><td>1995.0</td><td>1.8186e9</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>74.0</td><td>197.0</td><td>4.45</td><td>33.5</td><td>14.0</td><td>118.0</td><td>6.82</td><td>4.13</td></tr><tr><td>&quot;50%&quot;</td><td>2.0231e9</td><td>2170.0</td><td>null</td><td>49410.0</td><td>15.0</td><td>61.0</td><td>5.3559e18</td><td>0.5035</td><td>0.503565</td><td>2.71</td><td>1.92</td><td>179.61</td><td>180.19</td><td>10.0</td><td>0.50425</td><td>0.496248</td><td>1997.0</td><td>4.9139e11</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>75.0</td><td>209.0</td><td>4.52</td><td>35.5</td><td>17.0</td><td>122.0</td><td>6.96</td><td>4.23</td></tr><tr><td>&quot;75%&quot;</td><td>2.0231e9</td><td>3244.0</td><td>null</td><td>54496.0</td><td>22.0</td><td>80.0</td><td>5.4317e18</td><td>0.652</td><td>0.648593</td><td>4.6</td><td>3.04</td><td>270.84</td><td>271.66</td><td>14.0</td><td>0.653917</td><td>0.74803</td><td>1999.0</td><td>4.9139e11</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>77.0</td><td>229.0</td><td>4.62</td><td>37.5</td><td>19.0</td><td>126.0</td><td>7.09</td><td>4.34</td></tr><tr><td>&quot;max&quot;</td><td>2.0240e9</td><td>5258.0</td><td>1.0</td><td>56673.0</td><td>123.0</td><td>109.0</td><td>6.2266e18</td><td>0.998833</td><td>0.99212</td><td>12.53</td><td>17.12</td><td>360.0</td><td>360.0</td><td>94.0</td><td>1.04875</td><td>1.07561</td><td>2002.0</td><td>4.9139e11</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>83.0</td><td>384.0</td><td>6.05</td><td>46.5</td><td>49.0</td><td>147.0</td><td>9.12</td><td>5.56</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":309},{"cell_type":"code","source":"test_polars.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:19:09.677157Z","iopub.execute_input":"2025-11-26T05:19:09.677535Z","iopub.status.idle":"2025-11-26T05:19:09.713534Z","shell.execute_reply.started":"2025-11-26T05:19:09.677506Z","shell.execute_reply":"2025-11-26T05:19:09.712854Z"}},"outputs":[{"execution_count":310,"output_type":"execute_result","data":{"text/plain":"shape: (9, 48)\n┌────────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬──────────┬──────────┐\n│ statistic  ┆ game_id   ┆ play_id   ┆ player_to ┆ … ┆ Bench     ┆ Broad     ┆ 3Cone    ┆ Shuttle  │\n│ ---        ┆ ---       ┆ ---       ┆ _predict  ┆   ┆ ---       ┆ Jump      ┆ ---      ┆ ---      │\n│ str        ┆ f64       ┆ f64       ┆ ---       ┆   ┆ f64       ┆ ---       ┆ f64      ┆ f64      │\n│            ┆           ┆           ┆ f64       ┆   ┆           ┆ f64       ┆          ┆          │\n╞════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪══════════╪══════════╡\n│ count      ┆ 50013.0   ┆ 50013.0   ┆ 50013.0   ┆ … ┆ 22290.0   ┆ 24704.0   ┆ 20876.0  ┆ 22199.0  │\n│ null_count ┆ 7619.0    ┆ 7619.0    ┆ 7619.0    ┆ … ┆ 35342.0   ┆ 32928.0   ┆ 36756.0  ┆ 35433.0  │\n│ mean       ┆ 2.0244e9  ┆ 2083.6002 ┆ 0.267231  ┆ … ┆ 16.802557 ┆ 120.67385 ┆ 7.053552 ┆ 4.259298 │\n│            ┆           ┆ 44        ┆           ┆   ┆           ┆ 8         ┆          ┆          │\n│ std        ┆ 406498.31 ┆ 1201.7554 ┆ null      ┆ … ┆ 4.949528  ┆ 8.060606  ┆ 0.289234 ┆ 0.199295 │\n│            ┆ 1502      ┆ 75        ┆           ┆   ┆           ┆           ┆          ┆          │\n│ min        ┆ 2.0241e9  ┆ 63.0      ┆ 0.0       ┆ … ┆ 2.0       ┆ 74.0      ┆ 6.28     ┆ 3.73     │\n│ 25%        ┆ 2.0241e9  ┆ 1130.0    ┆ null      ┆ … ┆ 14.0      ┆ 117.0     ┆ 6.93     ┆ 4.15     │\n│ 50%        ┆ 2.0241e9  ┆ 2090.0    ┆ null      ┆ … ┆ 15.0      ┆ 120.0     ┆ 7.0      ┆ 4.23     │\n│ 75%        ┆ 2.0250e9  ┆ 3156.0    ┆ null      ┆ … ┆ 19.0      ┆ 126.0     ┆ 7.12     ┆ 4.35     │\n│ max        ┆ 2.0250e9  ┆ 4154.0    ┆ 1.0       ┆ … ┆ 49.0      ┆ 147.0     ┆ 9.12     ┆ 5.56     │\n└────────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴──────────┴──────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (9, 48)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>game_id</th><th>play_id</th><th>player_to_predict</th><th>nfl_id</th><th>frame_id</th><th>absolute_yardline_number</th><th>player_name</th><th>x</th><th>y</th><th>s</th><th>a</th><th>dir</th><th>o</th><th>num_frames_output</th><th>ball_land_x</th><th>ball_land_y</th><th>player_born_year</th><th>play_direction</th><th>player_role_Defensive Coverage</th><th>player_role_Other Route Runner</th><th>player_role_Passer</th><th>player_role_Targeted Receiver</th><th>player_position_CB</th><th>player_position_DE</th><th>player_position_DT</th><th>player_position_FB</th><th>player_position_FS</th><th>player_position_ILB</th><th>player_position_MLB</th><th>player_position_NT</th><th>player_position_OLB</th><th>player_position_QB</th><th>player_position_RB</th><th>player_position_S</th><th>player_position_SS</th><th>player_position_TE</th><th>player_position_WR</th><th>player_side_Defense</th><th>player_side_Offense</th><th>height</th><th>Wt</th><th>40yd</th><th>Vertical</th><th>Bench</th><th>Broad Jump</th><th>3Cone</th><th>Shuttle</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>327.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>50013.0</td><td>32632.0</td><td>30530.0</td><td>25664.0</td><td>22290.0</td><td>24704.0</td><td>20876.0</td><td>22199.0</td></tr><tr><td>&quot;null_count&quot;</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>57305.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>7619.0</td><td>25000.0</td><td>27102.0</td><td>31968.0</td><td>35342.0</td><td>32928.0</td><td>36756.0</td><td>35433.0</td></tr><tr><td>&quot;mean&quot;</td><td>2.0244e9</td><td>2083.600244</td><td>0.267231</td><td>51193.516786</td><td>16.014476</td><td>57.504089</td><td>6.1433e18</td><td>0.482949</td><td>0.501501</td><td>3.006484</td><td>2.048644</td><td>175.095483</td><td>184.27248</td><td>11.516846</td><td>0.492752</td><td>0.509933</td><td>1997.751885</td><td>2.6802e11</td><td>0.549857</td><td>0.288785</td><td>0.080679</td><td>0.080679</td><td>0.188651</td><td>0.005818</td><td>0.00162</td><td>0.002119</td><td>0.111591</td><td>0.062804</td><td>0.026793</td><td>0.00032</td><td>0.062704</td><td>0.080679</td><td>0.062964</td><td>0.005099</td><td>0.084458</td><td>0.096415</td><td>0.207966</td><td>0.549857</td><td>0.450143</td><td>75.046568</td><td>219.228947</td><td>4.598401</td><td>35.18081</td><td>16.802557</td><td>120.673858</td><td>7.053552</td><td>4.259298</td></tr><tr><td>&quot;std&quot;</td><td>406498.311502</td><td>1201.755475</td><td>null</td><td>5510.49243</td><td>10.570484</td><td>24.072299</td><td>3.4544e17</td><td>0.202122</td><td>0.183523</td><td>2.148734</td><td>1.287437</td><td>101.165637</td><td>98.540441</td><td>4.791391</td><td>0.209505</td><td>0.27439</td><td>3.083971</td><td>2.4385e11</td><td>0.497513</td><td>0.453202</td><td>0.272344</td><td>0.272344</td><td>0.391235</td><td>0.076058</td><td>0.040212</td><td>0.045989</td><td>0.314866</td><td>0.242612</td><td>0.16148</td><td>0.017884</td><td>0.242432</td><td>0.272344</td><td>0.2429</td><td>0.071223</td><td>0.278076</td><td>0.295162</td><td>0.405856</td><td>0.497513</td><td>0.497513</td><td>2.416545</td><td>31.507253</td><td>0.21363</td><td>3.844182</td><td>4.949528</td><td>8.060606</td><td>0.289234</td><td>0.199295</td></tr><tr><td>&quot;min&quot;</td><td>2.0241e9</td><td>63.0</td><td>0.0</td><td>38588.0</td><td>1.0</td><td>11.0</td><td>4.7143e18</td><td>0.01425</td><td>0.018386</td><td>0.0</td><td>0.0</td><td>0.01</td><td>0.0</td><td>5.0</td><td>0.021167</td><td>-0.015572</td><td>1990.0</td><td>1.8186e9</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>70.0</td><td>144.0</td><td>4.22</td><td>17.5</td><td>2.0</td><td>74.0</td><td>6.28</td><td>3.73</td></tr><tr><td>&quot;25%&quot;</td><td>2.0241e9</td><td>1130.0</td><td>null</td><td>46142.0</td><td>8.0</td><td>40.0</td><td>6.2265e18</td><td>0.333083</td><td>0.358912</td><td>1.15</td><td>1.04</td><td>86.71</td><td>94.59</td><td>8.0</td><td>0.36475</td><td>0.274859</td><td>1995.0</td><td>1.8186e9</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>73.0</td><td>199.0</td><td>4.48</td><td>32.5</td><td>14.0</td><td>117.0</td><td>6.93</td><td>4.15</td></tr><tr><td>&quot;50%&quot;</td><td>2.0241e9</td><td>2090.0</td><td>null</td><td>53496.0</td><td>15.0</td><td>60.0</td><td>6.2265e18</td><td>0.499</td><td>0.501876</td><td>2.76</td><td>1.89</td><td>169.65</td><td>188.89</td><td>11.0</td><td>0.525583</td><td>0.52758</td><td>1998.0</td><td>4.9139e11</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>75.0</td><td>210.0</td><td>4.54</td><td>35.5</td><td>15.0</td><td>120.0</td><td>7.0</td><td>4.23</td></tr><tr><td>&quot;75%&quot;</td><td>2.0250e9</td><td>3156.0</td><td>null</td><td>55949.0</td><td>22.0</td><td>79.0</td><td>6.2265e18</td><td>0.62975</td><td>0.642964</td><td>4.55</td><td>2.92</td><td>266.49</td><td>273.53</td><td>13.0</td><td>0.6325</td><td>0.72758</td><td>2000.0</td><td>4.9139e11</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>77.0</td><td>234.0</td><td>4.64</td><td>37.5</td><td>19.0</td><td>126.0</td><td>7.12</td><td>4.35</td></tr><tr><td>&quot;max&quot;</td><td>2.0250e9</td><td>4154.0</td><td>1.0</td><td>57801.0</td><td>60.0</td><td>109.0</td><td>6.2266e18</td><td>0.994667</td><td>0.964165</td><td>9.56</td><td>9.2</td><td>359.99</td><td>359.99</td><td>30.0</td><td>0.975833</td><td>0.991557</td><td>2003.0</td><td>4.9139e11</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>81.0</td><td>384.0</td><td>6.05</td><td>46.5</td><td>49.0</td><td>147.0</td><td>9.12</td><td>5.56</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":310},{"cell_type":"code","source":"def create_sequences(input_df, output_df):\n    \"\"\"\n    Create encoder-decoder sequences from input and output dataframes\n    \n    Args:\n        input_df: Tracking data BEFORE ball is thrown (encoder input)\n        output_df: Tracking data WHILE ball is in air (decoder target)\n    \n    Returns:\n        List of sequence dictionaries\n    \"\"\"\n    # Define feature columns\n    temporal_features = ['x', 'y', 's', 'a', 'dir', 'o']\n    \n    static_feature_cols = [\n        'height', 'Wt', '40yd', 'Vertical', 'Bench', \n        'Broad Jump', '3Cone', 'Shuttle', 'player_born_year',\n        'absolute_yardline_number', 'ball_land_x', 'ball_land_y',\n        'play_direction'\n    ] + [col for col in input_df.columns if col.startswith(\n        ('player_position_', 'player_role_', 'player_side_'))]\n    \n    # Convert to lazy if not already\n    input_lazy = input_df.lazy() if not isinstance(input_df, pl.LazyFrame) else input_df\n    output_lazy = output_df.lazy() if not isinstance(output_df, pl.LazyFrame) else output_df\n    \n    # Sort both dataframes\n    input_sorted = input_lazy.sort(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n    output_sorted = output_lazy.sort(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n    \n    # Group columns\n    group_cols = ['game_id', 'play_id', 'nfl_id']\n\n    #works since data is now in temporal format\n    \n    # Pre-compute aggregations using Polars' efficient group_by\n    input_agg = input_sorted.group_by(group_cols, maintain_order=True).agg([\n        *[pl.col(feat).alias(f'temporal_{feat}') for feat in temporal_features],\n        *[pl.col(col).first().alias(f'{col}_static') for col in static_feature_cols],\n        pl.len().alias('num_input_frames')\n    ])\n    \n    output_agg = output_sorted.group_by(group_cols, maintain_order=True).agg([\n        pl.col('x').alias('decoder_x'),\n        pl.col('y').alias('decoder_y'),\n        pl.len().alias('num_output_frames')\n    ])\n    \n    # Join the aggregated data and collect\n    joined = input_agg.join(output_agg, on=group_cols, how='inner').collect()\n    \n    # Convert to sequences\n    sequences = []\n    for row in joined.iter_rows(named=True):\n        # Extract temporal data - each feature is a list\n        temporal_data = np.column_stack([\n            row[f'temporal_{feat}'] for feat in temporal_features\n        ])\n        \n        # Extract static features\n        static_data = np.array([row[f'{col}_static'] for col in static_feature_cols], dtype=np.float32)\n        \n        # Repeat static features for each input frame\n        num_input_frames = row['num_input_frames']\n        static_repeated = np.tile(static_data, (num_input_frames, 1))\n        \n        # Combine temporal + static\n        encoder_input = np.concatenate([temporal_data, static_repeated], axis=1)\n        \n        # Decoder target\n        decoder_target = np.column_stack([\n            row['decoder_x'],\n            row['decoder_y']\n        ])\n        \n        sequences.append({\n            'encoder_input': encoder_input,\n            'decoder_target': decoder_target,\n            'static_features': static_data,\n            'num_input_frames': num_input_frames,\n            'num_output_frames': row['num_output_frames'],\n            'game_id': row['game_id'],\n            'play_id': row['play_id'],\n            'nfl_id': row['nfl_id']\n        })\n    \n    return sequences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:19:09.714267Z","iopub.execute_input":"2025-11-26T05:19:09.714467Z","iopub.status.idle":"2025-11-26T05:19:09.725538Z","shell.execute_reply.started":"2025-11-26T05:19:09.714449Z","shell.execute_reply":"2025-11-26T05:19:09.724449Z"}},"outputs":[],"execution_count":311},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n#scale data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:19:09.726388Z","iopub.execute_input":"2025-11-26T05:19:09.726604Z","iopub.status.idle":"2025-11-26T05:19:09.745917Z","shell.execute_reply.started":"2025-11-26T05:19:09.726585Z","shell.execute_reply":"2025-11-26T05:19:09.745149Z"}},"outputs":[],"execution_count":312},{"cell_type":"code","source":"# Fill any None/null values\ntrain_input_polars = train_input_polars.fill_null(0)\ntrain_output_polars = train_output_polars.fill_null(0)\nsequences = create_sequences(train_input_polars,train_output_polars)\nprint('one line')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:19:09.746792Z","iopub.execute_input":"2025-11-26T05:19:09.747530Z","iopub.status.idle":"2025-11-26T05:19:16.025852Z","shell.execute_reply.started":"2025-11-26T05:19:09.747496Z","shell.execute_reply":"2025-11-26T05:19:16.024856Z"}},"outputs":[{"name":"stdout","text":"one line\n","output_type":"stream"}],"execution_count":313},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nalpha = 0.001 #learning rate\nbatch_size = 32 #?\nhidden_size = 64\ninput_size = 41\nnum_layers = 2\nnum_classes = 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:19:16.026527Z","iopub.execute_input":"2025-11-26T05:19:16.026751Z","iopub.status.idle":"2025-11-26T05:19:16.031514Z","shell.execute_reply.started":"2025-11-26T05:19:16.026734Z","shell.execute_reply":"2025-11-26T05:19:16.030618Z"}},"outputs":[],"execution_count":314},{"cell_type":"code","source":"train_sequences, val_sequences = train_test_split(sequences, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:19:16.032346Z","iopub.execute_input":"2025-11-26T05:19:16.032555Z","iopub.status.idle":"2025-11-26T05:19:16.063122Z","shell.execute_reply.started":"2025-11-26T05:19:16.032538Z","shell.execute_reply":"2025-11-26T05:19:16.062332Z"}},"outputs":[],"execution_count":315},{"cell_type":"code","source":"train_dataset = EncoderDecoderDataset(train_sequences)\nval_dataset = EncoderDecoderDataset(val_sequences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:19:16.063923Z","iopub.execute_input":"2025-11-26T05:19:16.064175Z","iopub.status.idle":"2025-11-26T05:19:16.068864Z","shell.execute_reply.started":"2025-11-26T05:19:16.064156Z","shell.execute_reply":"2025-11-26T05:19:16.067609Z"}},"outputs":[],"execution_count":316},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size, shuffle=True,\n                         collate_fn=collate_fn_encoder_decoder, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size, shuffle=False,\n                       collate_fn=collate_fn_encoder_decoder, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:19:16.069711Z","iopub.execute_input":"2025-11-26T05:19:16.069946Z","iopub.status.idle":"2025-11-26T05:19:16.151895Z","shell.execute_reply.started":"2025-11-26T05:19:16.069923Z","shell.execute_reply":"2025-11-26T05:19:16.150907Z"}},"outputs":[],"execution_count":317},{"cell_type":"code","source":"sample = train_sequences[0]\nencoder_input_dim = sample['encoder_input'].shape[1]\nstatic_dim = len(sample['static_features'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:21:15.058460Z","iopub.execute_input":"2025-11-26T05:21:15.059380Z","iopub.status.idle":"2025-11-26T05:21:15.063816Z","shell.execute_reply.started":"2025-11-26T05:21:15.059347Z","shell.execute_reply":"2025-11-26T05:21:15.062876Z"}},"outputs":[],"execution_count":323},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"max_frames_in_data = 0\nfor batch in train_loader:\n    max_frames_in_data = max(max_frames_in_data, max(batch['output_lengths']))\n\nprint(f\"Max frames in dataset: {max_frames_in_data}\")\n\n# Create model with buffer\nmodel = EncoderDecoderRNN(\n    encoder_input_dim=encoder_input_dim,\n    static_dim=static_dim,\n    hidden_dim=128,\n    max_output_len=max_frames_in_data + 10,  # Add buffer\n    num_layers=2\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:21:16.518835Z","iopub.execute_input":"2025-11-26T05:21:16.519161Z","iopub.status.idle":"2025-11-26T05:21:21.759848Z","shell.execute_reply.started":"2025-11-26T05:21:16.519137Z","shell.execute_reply":"2025-11-26T05:21:21.758744Z"}},"outputs":[{"name":"stdout","text":"Max frames in dataset: 94\n","output_type":"stream"}],"execution_count":324},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='min', factor=0.5, patience=3\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:21:25.663332Z","iopub.execute_input":"2025-11-26T05:21:25.663647Z","iopub.status.idle":"2025-11-26T05:21:25.669412Z","shell.execute_reply.started":"2025-11-26T05:21:25.663616Z","shell.execute_reply":"2025-11-26T05:21:25.668609Z"}},"outputs":[],"execution_count":325},{"cell_type":"code","source":"#'''\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING\")\nprint(\"=\"*60)\n\nbest_val_loss = float('inf')\ntrain_losses = []\nval_losses = []\n\nfor epoch in range(NUM_EPOCHS):\n    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n    print(\"-\" * 60)\n    \n    # Train and validate\n    train_loss = train_epoch(model, train_loader, optimizer, device, \n                            teacher_forcing_ratio=0.5)\n    val_loss = validate_epoch(model, val_loader, device)\n    \n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    scheduler.step(val_loss)\n    \n    print(f\"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n    \n    # Save best model\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'train_loss': train_loss,\n            'val_loss': val_loss,\n            'encoder_input_dim': encoder_input_dim,\n            'static_dim': static_dim,\n            'hidden_dim': HIDDEN_DIM,\n            'num_layers': NUM_LAYERS\n        }, 'best_nfl_model.pth')\n        print(f\"✓ Saved best model\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(f\"TRAINING COMPLETE! Best Val Loss: {best_val_loss:.6f}\")\nprint(\"=\"*60)\n#'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:21:27.924060Z","iopub.execute_input":"2025-11-26T05:21:27.924767Z","iopub.status.idle":"2025-11-26T06:48:16.979419Z","shell.execute_reply.started":"2025-11-26T05:21:27.924730Z","shell.execute_reply":"2025-11-26T06:48:16.978046Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTRAINING\n============================================================\n\nEpoch 1/10\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1152/1152 [06:27<00:00,  2.98it/s]\nValidation: 100%|██████████| 288/288 [00:38<00:00,  7.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.111012 | Val Loss: 0.108446\n✓ Saved best model\n\nEpoch 2/10\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1152/1152 [07:17<00:00,  2.63it/s]\nValidation: 100%|██████████| 288/288 [00:37<00:00,  7.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.109164 | Val Loss: 0.109836\n\nEpoch 3/10\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1152/1152 [07:03<00:00,  2.72it/s]\nValidation: 100%|██████████| 288/288 [00:39<00:00,  7.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.109286 | Val Loss: 0.107994\n✓ Saved best model\n\nEpoch 4/10\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1152/1152 [07:11<00:00,  2.67it/s]\nValidation: 100%|██████████| 288/288 [00:39<00:00,  7.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.109353 | Val Loss: 0.108637\n\nEpoch 5/10\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1152/1152 [07:15<00:00,  2.65it/s]\nValidation: 100%|██████████| 288/288 [00:39<00:00,  7.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.109203 | Val Loss: 0.109943\n\nEpoch 6/10\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1152/1152 [08:36<00:00,  2.23it/s]\nValidation: 100%|██████████| 288/288 [00:40<00:00,  7.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.108882 | Val Loss: 0.108053\n\nEpoch 7/10\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1152/1152 [08:49<00:00,  2.17it/s]\nValidation: 100%|██████████| 288/288 [00:38<00:00,  7.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.108919 | Val Loss: 0.107568\n✓ Saved best model\n\nEpoch 8/10\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1152/1152 [09:13<00:00,  2.08it/s]\nValidation: 100%|██████████| 288/288 [00:39<00:00,  7.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.109155 | Val Loss: 0.107641\n\nEpoch 10/10\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1152/1152 [09:33<00:00,  2.01it/s]\nValidation: 100%|██████████| 288/288 [00:39<00:00,  7.31it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.109361 | Val Loss: 0.108409\n\n============================================================\nTRAINING COMPLETE! Best Val Loss: 0.107568\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":326},{"cell_type":"code","source":"#model = torch.load('/kaggle/working/best_nfl_model.pth',weights_only=\"True\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T05:19:21.419716Z","iopub.status.idle":"2025-11-26T05:19:21.421344Z","shell.execute_reply.started":"2025-11-26T05:19:21.421177Z","shell.execute_reply":"2025-11-26T05:19:21.421195Z"}},"outputs":[],"execution_count":null}]}